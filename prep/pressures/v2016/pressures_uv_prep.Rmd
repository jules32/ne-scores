---
title: 'OHIBC: Ultraviolet Anomalies Pressure layers prep'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohibc/src/templates/ohibc_hdr1.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = FALSE, message = FALSE, warning = FALSE)

library(sp)        # the classes and methods that make up spatial ops in R
library(rgdal)
library(raster)

dir_git <- '~/github/ohibc'
source(file.path(dir_git, 'src/R/common.R'))
  ### an OHIBC specific version of common.R
dir_anx <- file.path(dir_neptune_data, 'git-annex/bcprep')
dir_rgn <- file.path(dir_git, 'prep/regions')  ### github: general buffer region shapefiles

### goal specific folders and info
goal      <- 'pressures'
scenario  <- 'v2016'
dir_goal  <- file.path(dir_git, 'prep', goal, scenario)
dir_goal_anx <- file.path(dir_anx, goal, scenario)

### provenance tracking
source('~/github/ohibc/src/R/prov.R')      
  ### Provenance tracking functions: must source at start to initialize prov_track
dir_prov <- file.path(dir_goal, 'prov') 
  ### set a provenance folder for this script
this_script_file <- file.path(dir_goal, 'pressures_uv_prep.Rmd') 
  ### can't recognize the current script name on its own :(
prov_run_tag <- 'standard run'

### goal-specific source scripts
source(file.path(dir_goal, 'pressures_lyr_fxns.R'))

### other support functions
source(file.path(dir_git, 'src/R/rast_tools.R'))

### set up proj4string options: BC Albers and WGS84
p4s_wgs84 <- '+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0'
p4s_bcalb <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'

reload = FALSE
```

# Summary

There are two parts to creating this layer:

1. Data prep to get raw data into the correct format:
    * Read anomalies data as raster for 1997-2001 and 2010-2014.
    * Clip rasters to extents of OHIBC region, and reproject into BC Albers projection.
2. Creating the pressure layers for OHIBC:
    * Determine change in anomalies since baseline.
    * Set negative values to zero (only interested in increases).
    * Resample to 1 km.
    * Log transform results.
    * Interpolate to coastline at 1 km resolution.
    * Rescale zero to 1, where 1 is 99.99%ile
    
This process is completed entirely within this script.

# Updates

Not applicable.

# Data

The Ultraviolet Radiation pressures layer uses the Aura OMI GLobal Surface UVB Data Product.

* Native Data Resolution: 1 degree
* Values: Level-3 OMI Surface UV Irradiance and Erythemal Dose- OMUVBd
* Time Range: Daily data from 2004 - 2014
* Format: HDF5

# Methods

## Data Prep

### Read raw data

Raw data is read in for 1997-2001 and 2010-2014 datasets.

``` {r read_uv_layers}

dir_uv_data <- file.path(dir_neptune_data, 
                         'git-annex/globalprep/Pressures_UV', 
                         'data/uv_omi_aura_2013_2014/uv_baseline_anomaly')

gl_uv_curr <- raster(file.path(dir_uv_data, 
                               'omi_aura_uv_anomaly_2010m01-2014m12_raw.tif'))
gl_uv_past    <- raster(file.path(dir_uv_data, 
                                  'toms_ep_uv_anomaly_1997m01-2001m12_raw.tif'))
# data       = raster('uv_anomaly_difference_2010m01-2014m12_minus_1997m01-2001m12_raw.tif'))

range_uvpast    <- range(values(gl_uv_past), na.rm = TRUE)
range_uvcurr <- range(values(gl_uv_curr), na.rm = TRUE)

```

Range of UV~1997-2001~ for global dataset: `r paste(range_uvpast, collapse = ' - ')`.

Range of UV~2010-2014~ for global dataset: `r paste(range_uvcurr, collapse = ' - ')`.

### Convert raw global data to OHIBC region data

The raw data, in WGS84 coordinate ref system, is rasterized, clipped down to a bounding box around the OHIBC region, and reprojected into BC Albers projection.  This data is then resampled to 1 km resolution using nearest neighbor method.

The resulting raster layers include total UV anomalies for each coarse cell (approx 1 degree, from original resolution) the two time periods.

``` {r load_rgn, echo = FALSE}

rgn_lyr <- 'ohibc_rgn'

message(sprintf('Reading OHIBC regions shapefile...\n  %s/%s.shp', dir_rgn, rgn_lyr))
rgn_poly <- readOGR(dsn = path.expand(dir_rgn), layer = rgn_lyr,
                       verbose = FALSE, stringsAsFactors = FALSE)

rgn_poly_wgs84 <- readOGR(dsn = path.expand(dir_rgn), 
                         layer = paste(rgn_lyr, '_wgs84', sep = ''),
                         verbose = FALSE, stringsAsFactors = FALSE)

### In case we need to resample to 1 km... use base raster from 
### regions folder (note: 500m base raster available too).  Used later in
### finding zonal statistics anyway.
rast_rgn <- raster(file.path(dir_rgn, 'ohibc_rgn_raster_1000m.tif'))

```

``` {r create_uv_rasts, echo = FALSE}
### clip rasters to extents of region (in WGS 84 CRS)
### then: reproject to BC Albers projection
bc_uv_past_file <- file.path(dir_goal, 'int/uv/rast_uv_past_raw.tif')
bc_uv_curr_file <- file.path(dir_goal, 'int/uv/rast_uv_curr_raw.tif')


if(!file.exists(bc_uv_past_file) | reload) {
  message('Cropping raster layers from raw data')
  bc_uv_past <- raster::crop(gl_uv_past, rgn_poly_wgs84, snap = 'out') %>%
    raster::projectRaster(crs = p4s_bcalb)
  bc_uv_curr <- raster::crop(gl_uv_curr, rgn_poly_wgs84, snap = 'out') %>%
    raster::projectRaster(crs = p4s_bcalb)

  message('Resampling rasters to new resolution')
  bc_uv_past_resamp <- raster::resample(bc_uv_past, rast_rgn,
                               method   = 'ngb',
                               progress = 'text',
                               filename = bc_uv_past_file,
                               overwrite = TRUE)
  bc_uv_curr_resamp <- resample(bc_uv_curr, rast_rgn,
                               method   = 'ngb',
                               progress = 'text',
                               filename = bc_uv_curr_file,
                               overwrite = TRUE)
  
} else {
  message('Reading raster bricks from files')
  bc_uv_past_resamp <- raster(bc_uv_past_file)
  bc_uv_curr_resamp <- raster(bc_uv_curr_file)
}

plot_rast(bc_uv_past_resamp, 
          title = 'UV anomalies, 1997-2001', 
          scale_label = 'count',
          rev_scale = TRUE)

plot_rast(bc_uv_curr_resamp, 
          title = 'UV anomalies, 2010-2014', 
          scale_label = 'count',
          rev_scale = TRUE)

```


## Rescale values as pressures

Baseline UV anomaly frequency is based upon the count within 1997 to 2001.

Change in UV anomaly frequency is determined by simple subtraction of the 1997-2001 raster from the 2010-2014 raster.  Because the raw rasters seem to be on different grids, differences at native resolution cell edges are very uneven; so we interpolate each layer using thin plate spline before subtracting.

Values below zero (drop in UV anomaly frequency) are set to zero.

This difference value is log+1 transformed, then rescaled from zero (no change in anomalies) to 1 (at 99.99%ile of anomalies).

``` {r interpolate_uv_anomalies}

### because original data appear to be on different grids, interpolate
### each to create a more even surface - more sensible for subtraction.
### Col 3 is values from past raster, col 4 is values from current;
### use these to parameterize the tps_models
subset_n <- 2000 ### how many sample cells to use to create tps model

xy <- data.frame(xyFromCell(bc_uv_past_resamp, 1:ncell(bc_uv_past_resamp)))
tmpdf <- cbind(xy, getValues(bc_uv_past_resamp), getValues(bc_uv_curr_resamp)) %>%
  sample_n(min(subset_n, nrow(xy)))
xy1 <- tmpdf[ , 1:2]
v1  <- tmpdf[ , 3]
v2  <- tmpdf[ , 4]
tps_model1 <- fields::Tps(xy1, v1)
tps_model2 <- fields::Tps(xy1, v2)
message('interpolating uv past values')
bc_uv_past_int <- interpolate(bc_uv_past_resamp, tps_model1)
message('interpolating uv recent values')
bc_uv_curr_int <- interpolate(bc_uv_curr_resamp, tps_model2)

### mask to regions
values(bc_uv_past_int)[is.na(values(rast_rgn))] <- NA
values(bc_uv_curr_int)[is.na(values(rast_rgn))] <- NA

```

``` {r rescale_uv_pressures}

### determine change in anomalies
uv_delta <- bc_uv_curr_int - bc_uv_past_int

### If change in anomalies is negative, set to zero
values(uv_delta)[values(uv_delta) < 0] <- 0

plot_rast(uv_delta, 
          title = 'change in UV anomalies, 1997-2004 to 2010-2014', 
          scale_label = 'count',
          rev_scale = TRUE)

uv_delta_ln <- calc(uv_delta, fun = function(x) log(x + 1))

plot_rast(uv_delta_ln, 
          title = 'log+1 change in UV anomalies, 1997-2004 to 2010-2014', 
          scale_label = 'log(count+1)',
          rev_scale = TRUE)

ref_pt = quantile(uv_delta_ln, prob=0.9999)

uv_delta_resc <- calc(uv_delta_ln, fun = function(x) ifelse(x > ref_pt, 1, x/ref_pt))
plot_rast(uv_delta_resc, 
          title = 'rescaled change in UV anomalies, 1997-2004 to 2010-2014', 
          scale_label = 'scaled pressure',
          rev_scale = TRUE)

writeRaster(uv_delta_resc, file.path(dir_goal, 'output/uv/uv_rescaled_2010-2014.tif'), 
            overwrite = TRUE)

```


## Calculate mean pressure by region by year

Using 1000 m region ID raster to run zonal statistics on the pressures layers, calculate the regional average pressures for the study period, and save as a .csv.

``` {r calc_mean_uv_pressures_by_year}

uv_rgn_mean <- zonal(uv_delta_resc, rast_rgn, fun = 'mean') %>%
  as.data.frame() %>%
  rename(pressure = mean, rgn_id = zone) %>%
  left_join(rgn_poly@data %>% select(rgn_id, rgn_name), by = 'rgn_id')

knitr::kable(uv_rgn_mean)

write_csv(uv_rgn_mean, file.path(dir_goal, 'output/uv/uv_rgn_pressures.csv'))

```

-----

``` {r child = file.path(dir_git, 'src/templates/ohibc_prov_ftr.Rmd')}
```
